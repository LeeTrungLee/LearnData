from config.settings import POSTGRES_CONFIG, KAFKA_CONFIG, SPARK_CONFIG
from utils.logger import get_logger
from utils.scraper import scrape_website
from load.db_writer import write_to_postgres
from ingest.kafka_producer import send_to_kafka

logger = get_logger(__name__)

def main():
    logger.info("ğŸš€ Khá»Ÿi Ä‘á»™ng pipeline...")

    # Debug cáº¥u hÃ¬nh
    logger.debug(f"ğŸ“¦ PostgreSQL config: {POSTGRES_CONFIG}")
    logger.debug(f"ğŸ“¡ Kafka config: {KAFKA_CONFIG}")
    logger.debug(f"âš™ï¸ Spark config: {SPARK_CONFIG}")

    # Nháº­p URL
    source = input("ğŸ”— Nháº­p URL Ä‘á»ƒ cÃ o dá»¯ liá»‡u: ").strip()

    # CÃ o dá»¯ liá»‡u
    df = scrape_website(source)

    if df is not None and not df.empty:
        logger.info(f"âœ… Thu Ä‘Æ°á»£c {len(df)} dÃ²ng dá»¯ liá»‡u tá»« website.")
        print(df.to_string(index=False))

    else:
        logger.warning("âš ï¸ KhÃ´ng thu Ä‘Æ°á»£c dá»¯ liá»‡u nÃ o tá»« URL Ä‘Ã£ nháº­p.")
    
    send_to_kafka(df)

if __name__ == "__main__":
    main()
