from config.settings import POSTGRES_CONFIG, KAFKA_CONFIG, SPARK_CONFIG
from utils.logger import get_logger
from utils.scraper import scrape_website
from ingest.kafka_producer import produce_articles
from ingest.kafka_consumer import consume_and_save
import threading
import time

logger = get_logger(__name__)

def main():
    logger.info("ğŸš€ Khá»Ÿi Ä‘á»™ng pipeline...")

    logger.debug(f"ğŸ“¦ PostgreSQL config: {POSTGRES_CONFIG}")
    logger.debug(f"ğŸ“¡ Kafka config: {KAFKA_CONFIG}")
    logger.debug(f"âš™ï¸ Spark config: {SPARK_CONFIG}")

    consumer_thread = threading.Thread(target=consume_and_save, daemon=True)
    consumer_thread.start()
    logger.info("ğŸ“¡ Kafka consumer Ä‘ang cháº¡y á»Ÿ background...")

    url = "https://thanhnien.vn/"
    logger.info(f"ğŸ”— Äang cÃ o dá»¯ liá»‡u tá»«: {url}")
    df = scrape_website(url)

    if df is not None and not df.empty:
        logger.info(f"âœ… Thu Ä‘Æ°á»£c {len(df)} dÃ²ng dá»¯ liá»‡u.")
        print(df.to_string(index=False))

        produce_articles(df.to_dict(orient="records"))
        logger.info("ÄÃ£ gá»­i dá»¯ liá»‡u vÃ o Kafka.")
    else:
        logger.warning("KhÃ´ng thu Ä‘Æ°á»£c dá»¯ liá»‡u nÃ o.")


if __name__ == "__main__":
    main()
